{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T19:47:54.265550Z",
     "start_time": "2024-05-18T19:47:50.605804Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "%pip install opendatasets"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opendatasets\r\n",
      "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.2)\r\n",
      "Collecting kaggle (from opendatasets)\r\n",
      "  Downloading kaggle-1.6.14.tar.gz (82 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m82.1/82.1 kB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: click in /home/sajjad/.local/lib/python3.10/site-packages (from opendatasets) (7.1.2)\r\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\r\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/sajjad/.local/lib/python3.10/site-packages (from kaggle->opendatasets) (2023.11.17)\r\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\r\n",
      "Collecting python-slugify (from kaggle->opendatasets)\r\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: requests in /home/sajjad/.local/lib/python3.10/site-packages (from kaggle->opendatasets) (2.31.0)\r\n",
      "Requirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle->opendatasets) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3 in /home/sajjad/.local/lib/python3.10/site-packages (from kaggle->opendatasets) (2.1.0)\r\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\r\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle->opendatasets)\r\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sajjad/.local/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sajjad/.local/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.6)\r\n",
      "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\r\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\r\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.2/78.2 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: kaggle\r\n",
      "  Building wheel for kaggle (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for kaggle: filename=kaggle-1.6.14-py3-none-any.whl size=105137 sha256=06e3714df83709d7cf326c88817f0f00d976254115cc3cb2ff888a1ddc077c06\r\n",
      "  Stored in directory: /home/sajjad/.cache/pip/wheels/d7/54/06/8a8f40cb39536605feb9acaacd0237a95eba39e5065e6392f4\r\n",
      "Successfully built kaggle\r\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle, opendatasets\r\n",
      "\u001B[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '/usr/local/bin/slugify'\r\n",
      "Consider using the `--user` option or check the permissions.\r\n",
      "\u001B[0m\u001B[31m\r\n",
      "\u001B[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T19:51:57.568644Z",
     "start_time": "2024-05-18T19:51:54.622344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ],
   "id": "2436d7cc38aed051",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 20:51:55.771069: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-18 20:51:56.742831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:20:03.197097Z",
     "start_time": "2024-05-18T20:16:55.384191Z"
    }
   },
   "cell_type": "code",
   "source": "od.download('https://www.kaggle.com/datasets/alxmamaev/flowers-recognition')",
   "id": "e187e52df432bde9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: Your Kaggle Key: Dataset URL: https://www.kaggle.com/datasets/alxmamaev/flowers-recognition\n",
      "Downloading flowers-recognition.zip to ./flowers-recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225M/225M [02:30<00:00, 1.56MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:20:49.970914Z",
     "start_time": "2024-05-18T20:20:49.967218Z"
    }
   },
   "cell_type": "code",
   "source": "data_dir = 'flowers-recognition'\n",
   "id": "176f198a7c75d0c8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:20:52.096044Z",
     "start_time": "2024-05-18T20:20:52.092353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_height, img_width = 224, 224\n",
    "batch_size = 32"
   ],
   "id": "c3ea36015407d180",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:20:53.564833Z",
     "start_time": "2024-05-18T20:20:53.560669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "                                   validation_split=0.2)"
   ],
   "id": "709272bdcfea4507",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:20:56.127349Z",
     "start_time": "2024-05-18T20:20:56.059241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = train_datagen.flow_from_directory(data_dir, target_size=(img_height, img_width), batch_size=batch_size,\n",
    "                                                  class_mode='categorical', subset='training')"
   ],
   "id": "9529cc5698bf983a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3454 images belonging to 1 classes.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:22:16.668620Z",
     "start_time": "2024-05-18T20:22:16.640278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_data = train_datagen.flow_from_directory(data_dir, target_size=(img_height, img_width), class_mode='categorical',\n",
    "                                             batch_size=batch_size, subset='validation')"
   ],
   "id": "76837f020f92f2f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 863 images belonging to 1 classes.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:24:51.140616Z",
     "start_time": "2024-05-18T20:24:51.039463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "id": "e279841d475c6038",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:30:13.555429Z",
     "start_time": "2024-05-18T20:30:13.551144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_flowers(img):\n",
    "    image = tf.image.resize(img, (img_height, img_width))\n",
    "    image = image / 255.0\n",
    "    prediction = model.predict(np.array([image]))\n",
    "    class_names = ['daisy', 'dandelion', 'roses', 'sunflower', 'tulips']\n",
    "    return {class_names[i]: float(prediction[0][i]) for i in range(len(class_names))}"
   ],
   "id": "3e08bd56e8048fbd",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T20:37:25.566817Z",
     "start_time": "2024-05-18T20:37:25.467485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=classify_flowers,\n",
    "    inputs=gr.components.Image(),\n",
    "    outputs=gr.components.Label(num_top_classes=5),\n",
    "    title='Flower Classification',\n",
    "    examples=['flowers-recognition/flowers/daisy/5547758_eea9edfd54_n.jpg']\n",
    ")\n",
    "iface.launch()\n"
   ],
   "id": "1b121ce293cfef66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
